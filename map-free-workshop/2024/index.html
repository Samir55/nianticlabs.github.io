<!doctype html>
<html lang="en">

<head>
    <title>Map-free Visual Relocalization: Metric Pose Relative to a Single Image</title>
    <meta name="description" content="Map-free visual relocalization ECCV 2024 workshop"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes"/>
    <meta charset="utf-8"/>
    <link rel="icon" href="assets/images/NianticLogo.png"/>

    <!--Facebook preview-->
    <meta property="og:title"
          content="Map-free Visual Relocalization: Metric Pose Relative to a Single Image"/>
    <meta property="og:description"
          content="Map-free Visual Relocalization Competition. An ECCV'24 workshop."/>
    <meta property="og:url" content="https://TODO"/>

    <!--Twitter preview-->
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:title"
          content="Map-free Visual Relocalization: Metric Pose Relative to a Single Image"/>
    <meta name="twitter:description"
          content="Map-free Visual Relocalization Competition. An ECCV'24 workshop."/>

    <!--Style-->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH"
          crossorigin="anonymous"/>

    <link href="css/style.css" rel="stylesheet"/>
    <script src="https://kit.fontawesome.com/746ee6bfa4.js" crossorigin="anonymous"></script>

    <!--<script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>-->
    <!--<script src="js/app.js"></script>-->
</head>

<body>
<div class="container">
    <div class="row" style="text-align:center">
        <div class="col">
            <h1 style="margin-bottom:1.3rem;">Map-free Visual Relocalization:<br/>
                Metric Pose Relative to a Single Image</h1>
            <h4 style="font-size:1.7em;">ECCV 2024 Workshop & Challenge</h4>
        </div> <!-- col -->
    </div> <!-- row -->

    <div class="row" style="text-align:center; margin-top:1rem;">
        <div class="col-12">
            <h4>
                <a style="font-size:1.1em; text-decoration: none;"
                   href="https://research.nianticlabs.com/mapfree-reloc-benchmark/leaderboard">
                    <nobr>Leaderboard <small>(Track 1)</small></nobr>
                </a> &emsp;
                <a style="font-size:1.1em; text-decoration: none; color: #444;"
                   href="#">
                    <nobr>Leaderboard <small>(Track 2)</small></nobr>
                </a> &emsp;
                <a style="font-size:1.1em; text-decoration: none;"
                   href="https://research.nianticlabs.com/mapfree-reloc-benchmark/dataset">
                    <nobr>Dataset</nobr>
                </a> &emsp;
                <a style="font-size:1.1em; text-decoration: none;"
                   href="https://github.com/nianticlabs/map-free-reloc#bar_chart-evaluate-your-method">
                    <nobr>Benchmark</nobr>
                </a> &emsp;
                <a style="font-size:1.1em; text-decoration: none;"
                   href="https://research.nianticlabs.com/mapfree-reloc-benchmark/submit">
                    <nobr>Submit</nobr>
                </a> &emsp;
                <!--<a style="font-size:1.1em; text-decoration: none;" href="TODO">
                    <nobr>Call for papers</nobr>
                </a>-->
            </h4>
        </div> <!-- col -->
    </div> <!-- row -->

    <div class="row">
        <div class="col-12">
            <!--<img src="assets/images/teaser.jpg"
                 style="display: block; margin: auto; width: 80%; margin-bottom: 1rem;"
                 alt="teaser image"/>-->
            <video width="100%" controls autoplay muted loop style="border-radius: 2%">
                <source src="assets/images/web_mapfree.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </div> <!-- col -->
    </div> <!-- row -->

    <div class="row">
        <div class="col-12">
            <p>
                The Map-free Visual Relocalization workshop investigates topics related to
                metric visual relocalization relative to a single reference image instead of
                relative to a map.
                This problem is of major importance to many higher level applications, such as
                Augmented/Mixed Reality, SLAM and 3D reconstruction.
                It is important now, because both industry and academia are debating whether and
                how to build HD-maps of the world for those tasks. Our community is working to
                reduce the need for such maps in the first place.
                <br/>
                <br/>
                We host the first Map-free Visual Relocalization Challenge 2024 competition with
                two tracks:
                map-free metric relative pose from a single image to a single image (proposed by
                <a href="https://github.com/nianticlabs/map-free-reloc">Arnold et al. in ECCV
                    2022</a>) and from a query sequence to a single image (new).
                While the former is a more challenging and thus interesting research topic, the
                latter represents a more realistic relocalization scenario, where the system making
                the queries may fuse information from query images and tracking poses over a short
                amount of time and baseline.
                We invite papers to be submitted to the workshop.
            </p>
        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <div class="row">
        <div class="col-12">
            <h3><a id="About_the_Challenge">About the Challenge</a><!--
            --><small><!--
              --><a
                    onclick="copyLinkToClipboard('About_the_Challenge');"
                    style="cursor: pointer;"> 🔗<!--
              --></a><!--
            --></small><!--
         --></h3>
            <hr/>
            <p>
                We are extending the Map-free benchmark for the challenge with a sequence-based
                scenario, based on feedback from senior community members.
                Therefore, the challenge will consist of two tracks:<br/>
                &nbsp;&nbsp; 1. The original, <strong>single query frame</strong> to single map
                frame task published
                with the <a
                    href="https://storage.googleapis.com/niantic-lon-static/research/map-free-reloc/MapFreeReloc-ECCV22-paper.pdf"
                    target="_blank">ECCV 2022 paper</a>;<br/>
                &nbsp;&nbsp; 2. A new task with <strong>multiple query frames</strong> (9) and their
                mobile device provided, metric tracking poses.
            </p>
            <h5> 1. Single query frame to a single "map" frame</h5>
            <p>
                To recap, the task in the first track consists of from a single query image predict
                the
                metric relative pose to a single map image without any further auxiliary
                information.
            </p>
            <h5> 2. Multiple query frames (9) to a single "map" frame</h5>
            <p>
                The second track is motivated by the observation that a burst of images, capturing
                small motion, can be recorded while staying true to the map-free scenario: No
                significant data capture or exploration of the environment.<br/>
                At the same time, the burst of images allows the application of multi-frame depth
                estimation and contains strong hints about the scene scale from the IMU sensor on
                device.<br/>
                We are creating a second version of the test set and leaderboard for this track.
            </p>
        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <div class="row">
        <div class="col-12">
            <h3><a id="Important_Dates">Important Dates</a><!--
            --><small><!--
              --><a
                    onclick="copyLinkToClipboard('Important_Dates');"
                    style="cursor: pointer;"> 🔗<!--
              --></a><!--
            --></small><!--
         --></h3>
            <hr/>
            <ul>
                <li>
                    <strong>Challenge start:</strong>
                    TBD (~16<sup>th</sup> May, 2024)
                </li>
                <li>
                    <strong>Challenge submission deadline:</strong>
                    TBD (~2<sup>nd</sup> August, 2024)
                </li>
                <li>
                    <strong>Challenge submission short description deadline:</strong>
                    TBD (~16<sup>th</sup> August, 2024)
                </li>
                <li>
                    <strong>Paper camera-ready deadline:</strong>
                    TBD (~23<sup>rd</sup> August, 2024)
                </li>
                <li>
                    <strong>Workshop date (ECCV'24):</strong>
                    30<sup>th</sup> September, 2024
                    <small><a
                        href="http://www.google.com/calendar/event?action=TEMPLATE&dates=20240930T070000Z/20240930T110000Z&text=Map-free%20Visual%20Relocalization%20Workshop%20at%20ECCV%202024%20&location=Allianz+MiCo+%E2%80%A2+Milano+Convention+Centre&details=Map-free%20Visual%20Relocalization%20Workshop%20at%20ECCV%202024%0Ahttps%3A%2F%2Fnianticlabs.github.io%2Fmap-free-workshop%2F2024%20%0A%0AGoogle%20Maps%3A%20https%3A%2F%2Fmaps.app.goo.gl%2Fif1ooCakSvhiEPmR7"
                        target="_blank">
                    [Add to Google Calendar]</a></small>
                </li>
            </ul>
        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <div class="row">
        <div class="col-12">
            <h3><a id="Prizes">Prizes</a><!--
            --><small><!--
              --><a
                    onclick="copyLinkToClipboard('Prizes');"
                    style="cursor: pointer;"> 🔗<!--
              --></a><!--
            --></small><!--
         --></h3>
            <hr/>
            <p>
                $3000 in prizes will be awarded to the top submissions in each of the two tracks. <br />
                Niantic is also seeking partners from the growing community to co-fund and co-judge
                the prizes.
            </p>
        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->
    <div class="row">
        <div class="col-12">
            <h3><a id="Speakers">Speakers</a><!--
            --><small><!--
              --><a
                    onclick="copyLinkToClipboard('Speakers');"
                    style="cursor: pointer;"> 🔗<!--
              --></a><!--
            --></small><!--
         --></h3>
            <hr/>

            <div class="speaker" style="margin-bottom:3rem;">
                <img src="assets/speakers/jakob.jpeg" alt="Speaker Image" class="speaker-image"/>
                <div class="speaker-info">
                    <h4 class="speaker-name">
                        <a href="https://jakobengel.github.io/"
                           style="text-decoration: none;" id="Speakers__Jakob_Engel">
                            Jakob Engel<!--
                     --></a>, Meta
                    </h4>
                    <p class="speaker-bio">
                        <span class="talk-title">Talk title:</span> TBC
                    </p>
                    <p class="speaker-bio">
                        Jakob Engel joined the Surreal Vision team at Oculus Research in Redmond in
                        2016, working on the future of 3D-enabled Machine Perception.
                        He did his Bachelor and Master at TU Munich (2009 and 2012), followed up
                        with a PhD at the Computer Vision Group there, headed by Professor Daniel
                        Cremers.
                        He spent 6 months as Intern at Intel Research with Vladlen Koltun, was a
                        Google PhD fellow, and worked with SIEMENS within the Software Campus
                        Initiative.
                        His PhD was about direct visual SLAM, 3D reconstruction, sensor fusion and
                        some cool flying quadrocopter stuff - mostly he developed LSD-SLAM and DSO.
                    </p>
                </div>
            </div> <!-- speaker -->

            <div class="speaker" style="margin-bottom:3rem;">
                <img src="assets/speakers/simon.webp" alt="Speaker Image" class="speaker-image"/>
                <div class="speaker-info">
                    <h4 class="speaker-name">
                        <a href="https://research.google/people/simon-lynen/"
                           style="text-decoration: none;" id="Speakers__Simon_Lynen">
                            Simon Lynen<!--
                     --></a>, Google <small>(or a member of the VPS team, TBC)</small>
                    </h4>
                    <p class="speaker-bio">
                        <span class="talk-title">Talk title:</span> TBC
                    </p>
                    <p class="speaker-bio">
                        Simon Lynen is a tech lead manager at Google Zurich.
                        His group focuses on providing high precision mobile-phone localization as
                        part of the Visual Positioning Service (VPS).
                        Devices with Google’s augmented reality capabilities can leverage VPS to
                        enable global scale location aware experiences such as ARCore CloudAnchors
                        and GoogleMaps LiveView.
                        Simon earned a doctorate at the Autonomous Systems Lab at ETH Zurich with a
                        focus on visual navigation and localization algorithms for robotics, mobile
                        devices, and autonomous cars.
                        As visiting researcher, Simon contributed central pieces to core algorithms
                        of Google’s ARCore.
                        In talks at TEDx Zurich, ThinkingDigital, Zurich Minds, and scientific
                        conferences, Simon has provided a behind-the-scenes view of the ARCore
                        technology and its latest capabilities.
                    </p>
                </div>
            </div> <!-- speaker -->

            <div class="speaker" style="margin-bottom:3rem;">
                <img src="assets/speakers/torsten.jpg" alt="Speaker Image" class="speaker-image"/>
                <div class="speaker-info">
                    <h4 class="speaker-name">
                        <a href="https://tsattler.github.io/"
                           style="text-decoration: none;" id="Speakers__Torsten_Sattler">
                            Torsten Sattler<!--
                     --></a>, CTU Prague
                    </h4>
                    <p class="speaker-bio">
                        <span class="talk-title">Talk title:</span> TBC
                    </p>
                    <p class="speaker-bio">
                        Torsten Sattler is a Senior Researcher at CTU.
                        Before, he was a tenured associate professor at Chalmers University of
                        Technology.
                        He received a PhD in Computer Science from RWTH Aachen University, Germany,
                        in 2014.
                        From Dec. 2013 to Dec. 2018, he was a post-doctoral and senior researcher at
                        ETH Zurich.
                        Torsten has worked on feature-based localization methods [PAMI’17],
                        long-term localization [CVPR’18, ICCV’19, ECCV’20, CVPR’21] (see also the
                        benchmarks
                        at <a href="https://visuallocalization.net" target="_blank">visuallocalization.net</a>),
                        localization on mobile devices [ECCV’14, IJRR’20], and using semantic scene
                        understanding for localization [CVPR’18, ECCV’18, ICCV’19].
                        Torsten has co-organized tutorials and workshops at CVPR (’14, ’15,
                        ’17-’20), ECCV (’18, ’20), and ICCV (’17, ’19), and was / is an area chair
                        for CVPR (’18, ’22, ’23), ICCV (’21, ’23), 3DV (’18-’21), GCPR (’19, ’21),
                        ICRA (’19, ’20), and ECCV (’20).
                        He was a program chair for DAGM GCPR’20, a general chair for 3DV’22, and
                        will be a program chair for ECCV’24.
                    </p>
                </div>
            </div> <!-- speaker -->

            <div class="speaker" style="margin-bottom:3rem;">
                <img src="assets/speakers/shubham.jpg" alt="Speaker Image" class="speaker-image"/>
                <div class="speaker-info">
                    <h4 class="speaker-name">
                        <a href="https://shubhtuls.github.io/"
                           style="text-decoration: none;" id="Speakers__Shubham_Tulsiani">
                            Shubham Tulsiani<!--
                     --></a>, Carnegie Mellon University
                    </h4>
                    <p class="speaker-bio"><span class="talk-title">Talk title:</span>
                        TBC
                    </p>
                    <p class="speaker-bio">
                        Shubham Tulsiani is an Assistant Professor at Carnegie Mellon University in
                        the Robotics Institute.
                        Prior to this, he was a research scientist at Facebook AI Research (FAIR).
                        He received a PhD. in Computer Science from UC Berkeley in 2018 where his
                        work was supported by the Berkeley Fellowship.
                        He is interested in building perception systems that can infer the spatial
                        and physical structure of the world they observe.
                        He was the recipient of the Best Student Paper Award in CVPR 2015.
                    </p>
                </div>
            </div> <!-- speaker -->

            <div class="speaker" style="margin-bottom:3rem;">
                <img src="assets/organizers/victor.jpg" alt="Speaker Image" class="speaker-image"/>
                <div class="speaker-info">
                    <h4 class="speaker-name">
                        <a href="https://www.robots.ox.ac.uk/~victor/"
                           style="text-decoration: none;" id="Speakers__Victor_Adrian_Prisacariu">
                            Victor Adrian Prisacariu<!--
                     --></a>, Niantic and Oxford University
                    </h4>
                    <p class="speaker-bio">
                        <span class="talk-title">Talk title:</span> TBC (opening remarks)
                    </p>
                    <p class="speaker-bio">
                        Professor Victor Adrian Prisacariu received the Graduate degree (with first
                        class hons.) in computer engineering from Gheorghe Asachi Technical
                        University, Iasi, Romania, in 2008, and the D.Phil. degree in engineering
                        science from the University of Oxford in 2012.<br/>
                        He continued here first as an EPSRC prize Postdoctoral Researcher, and then
                        as a Dyson Senior Research Fellow, before being appointed an Associate
                        Professor in 2017.
                        <br/>
                        He also co-founded <a href="https://6D.ai">6D.ai</a>, where he built APIs to
                        help developers augment reality in ways that users would find meaningful,
                        useful and exciting.
                        The 6D.ai SDK used a standard built-in smartphone camera to build a
                        cloud-based, crowdsourced three-dimensional semantic map of the world all in
                        real-time, in the background.
                        6D.ai was acquired by Niantic in March 2020. He is now Chief Scientist with
                        Niantic.
                        <br/>
                        Victor's research interests include semantic visual tracking, 3-D
                        reconstruction, and SLAM.
                    </p>
                </div>
            </div> <!-- speaker -->

        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <div class="row">
        <div class="col-12">
            <h3><a id="Schedule">Preliminary Schedule</a><!--
            --><small><!--
              --><a
                    onclick="copyLinkToClipboard('Schedule');"
                    style="cursor: pointer;"> 🔗<!--
              --></a><!--
            --></small><!--
         --></h3>
            <hr/>
            <table class="table">
                <thead>
                <tr>
                    <th scope="col">Time</th>
                    <th scope="col">Event</th>
                </tr>
                </thead>
                <tbody>
                <tr>
                    <td>09:00-09:10</td>
                    <td>
                        Welcome introduction by <a href="https://www.robots.ox.ac.uk/~victor/"
                                                   style="text-decoration: none;">
                        Victor Adrian Prisacariu</a> (Niantic and Oxford University)
                    </td>
                </tr>
                <tr>
                    <td>09:10-09:40</td>
                    <td>Invited Talk (Talk 1)</td>
                </tr>
                <tr>
                    <td>09:40-10:10</td>
                    <td>Invited Talk (Talk 2)</td>
                </tr>
                <tr>
                    <td>10:10-10:40</td>
                    <td>Invited Talk (Talk 3)</td>
                </tr>
                <tr>
                    <td>10:40-10:55</td>
                    <td>Coffee break</td>
                </tr>
                <tr>
                    <td>10:55-11:10</td>
                    <td>Winner Talk 1 (Track 1)</td>
                </tr>
                <tr>
                    <td>11:10-11:25</td>
                    <td>Winner Talk 2 (Track 2)</td>
                </tr>
                <tr>
                    <td>11:25-11:55</td>
                    <td>Invited Talk (Talk 4)</td>
                </tr>
                <tr>
                    <td>11:55-12:10</td>
                    <td>Roundtable discussion</td>
                </tr>
                <tr>
                    <td>12:10-12:15</td>
                    <td>Closing Remarks</td>
                </tr>
                </tbody>
            </table>
        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <div class="row align-items-center">
        <div class="col-12">
            <h3><a id="Organizers">Organizers</a><!--
            --><small><!--
              --><a
                    onclick="copyLinkToClipboard('Organizers');"
                    style="cursor: pointer;"> 🔗<!--
              --></a><!--
            --></small><!--
         --></h3>
            <hr/>
        </div> <!-- col -->
    </div>

    <div class="row justify-content-center">
        <div class="col mugshot-item">
            <a href="https://amonszpart.github.io/">
                <img class="headshot" src="assets/organizers/aron.jpeg"/>
                <span class="name">Áron Monszpart</span>
                <span class="affiliation">Niantic</span>
            </a>
        </div> <!-- col -->
        <div class="col mugshot-item">
            <a href="https://ebrach.github.io/">
                <div class="item">
                    <img class="headshot" src="assets/organizers/eric.jpeg"/>
                    <span class="name">Eric Brachmann</span>
                    <span class="affiliation">Niantic</span>
                </div><!--
         --></a>
        </div> <!-- col -->
        <div class="col mugshot-item">
            <a href="https://scholar.google.com/citations?user=bSxMRawAAAAJ">
                <div class="item">
                    <img class="headshot" src="assets/organizers/filipe.jpeg"/>
                    <span class="name">Filipe Gaspar</span>
                    <span class="affiliation">Niantic</span>
                </div><!--
         --></a>
        </div> <!-- col -->
        <div class="col mugshot-item">
            <a href="https://guiggh.github.io/">
                <div class="item">
                    <img class="headshot" src="assets/organizers/guillermo.jpeg"/>
                    <span class="name">Guillermo Garcia-Hernando</span>
                    <span class="affiliation">Niantic</span>
                </div><!--
         --></a>
        </div> <!-- col -->
        <div class="col mugshot-item">
            <a href="https://scholar.google.com/citations?user=m_SPRGUAAAAJ&hl=en">
                <div class="item">
                    <img class="headshot" src="assets/organizers/axel.jpeg"/>
                    <span class="name">Axel Barroso-Laguna</span>
                    <span class="affiliation">Niantic</span>
                </div><!--
         --></a>
        </div> <!-- col -->
        <div class="col mugshot-item">
            <a href="https://dantkz.github.io/about/">
                <div class="item">
                    <img class="headshot" src="assets/organizers/daniyar.jpeg"/>
                    <span class="name">Daniyar Turmukhambetov</span>
                    <span class="affiliation">Niantic</span>
                </div><!--
         --></a>
        </div> <!-- col -->
        <div class="col mugshot-item">
            <a href="http://web4.cs.ucl.ac.uk/staff/g.brostow/">
                <div class="item">
                    <img class="headshot" src="assets/organizers/gabriel.jpeg"/>
                    <span class="name">Gabriel J. Brostow</span>
                    <span class="affiliation">Niantic, University College London</span>
                </div><!--
         --></a>
        </div> <!-- col -->
        <div class="col mugshot-item">
            <a href="https://www.robots.ox.ac.uk/~victor/">
                <div class="item">
                    <img class="headshot" src="assets/organizers/victor.jpg"/>
                    <span class="name">Victor Adrian Prisacariu</span>
                    <span class="affiliation">Niantic, University of Oxford</span>
                </div><!--
         --></a>
        </div> <!-- col -->
    </div> <!-- row -->

    <div class="row justify-content-center">
        <div class="col-12">
            <h3><a id="Sponsors">Sponsors</a></h3>
            <hr/>
            <div class="row justify-content-center">
                <div class="col d-flex justify-content-center">
                    <img alt="Niantic" src="assets/images/NianticLogo-Large.png"
                         style="height: 100px;"/>
                </div>
            </div>
        </div> <!-- col -->
    </div> <!-- row -->
</div> <!-- container -->

<!-- --------------------------------------------------------------------------------------- -->

<footer style="display: flex; justify-content: center; align-items: center; flex-direction: column;">
    <section>
        <p style="text-align: center;">&copy; 2024 Map-free Challenge organizers</p>
        <p style="text-align: center;">
            <a href="https://github.com/nianticlabs/map-free-reloc">GitHub</a>
            <a href="mailto:map-free-workshop@nianticlabs.com" target="_blank">E-mail</a>
        </p>
    </section>
</footer>

<!--<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.8/dist/umd/popper.min.js" integrity="sha384-I7E8VVD/ismYTF4hNIPjVp/Zjvgyol6VFvRkX/vR+Vc4jQkC+hVqc2pM8ODewa9r" crossorigin="anonymous"></script>-->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.min.js"
        integrity="sha384-0pUGZvbkm6XF6gxjEnlmuGrJXVbNuzT9qBBavbLwCsOGabYfZo0T0to5eqruptLy"
        crossorigin="anonymous"></script>

<script>
function copyLinkToClipboard(link_name) {
    let parts = window.location.href.split('#');
    let url = parts[parts.length - 2] + '#' + link_name;
    navigator.clipboard.writeText(url);
}
</script>

</body>
</html>
